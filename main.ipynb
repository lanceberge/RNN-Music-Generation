{"cells":[{"cell_type":"code","execution_count":1,"id":"0a85f68a","metadata":{"id":"0a85f68a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651107470604,"user_tz":240,"elapsed":21962,"user":{"displayName":"Lance Bergeron","userId":"12580516453162994131"}},"outputId":"110c8f51-d015-4361-b74f-1f3a8f036b96"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting mido\n","  Downloading mido-1.2.10-py2.py3-none-any.whl (51 kB)\n","\u001b[?25l\r\u001b[K     |██████▍                         | 10 kB 18.0 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 20 kB 20.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 30 kB 11.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 40 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51 kB 3.0 MB/s \n","\u001b[?25hInstalling collected packages: mido\n","Successfully installed mido-1.2.10\n","Mounted at /content/drive/\n"]}],"source":["import os\n","import string\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import random\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","\n","# if using google colab - set up path properly\n","if 'google.colab' in str(get_ipython()):\n","    !pip install mido\n","\n","    from google.colab import drive\n","    drive.mount('/content/drive/')\n","\n","    import sys\n","    cwd = '/content/drive/My Drive/school/stat4984/final_proj/'\n","    sys.path.append(cwd)\n","\n","else:\n","    cwd = os.getcwd()+'/'\n","\n","# set up directories\n","midi_data_dir = cwd+'midi_data/'\n","csv_data_dir  = cwd+'csv_data/'\n","\n","if not os.path.exists(midi_data_dir):\n","    os.makedirs(midi_data_dir)\n","\n","if not os.path.exists(midi_data_dir):\n","    os.makedirs(csv_data_dir)\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":2,"id":"c33f11e6","metadata":{"id":"c33f11e6","executionInfo":{"status":"ok","timestamp":1651107470605,"user_tz":240,"elapsed":8,"user":{"displayName":"Lance Bergeron","userId":"12580516453162994131"}}},"outputs":[],"source":["def dir_idx(dir_name, n):\n","    \"\"\"\n","    return the name of the nth file in a directory\n","    \"\"\"\n","    \n","    return dir_name+os.listdir(dir_name)[n]"]},{"cell_type":"markdown","id":"caed195a","metadata":{"id":"caed195a"},"source":["# Data Preprocessing"]},{"cell_type":"code","execution_count":3,"id":"dabc932d","metadata":{"scrolled":true,"id":"dabc932d","executionInfo":{"status":"ok","timestamp":1651107476313,"user_tz":240,"elapsed":147,"user":{"displayName":"Lance Bergeron","userId":"12580516453162994131"}}},"outputs":[],"source":["# only download midis if the batch dir doesn't exist and midi dir is empty\n","if len(os.listdir(midi_data_dir)) == 0 and len(os.listdir(csv_data_dir)) == 0:\n","    import mido\n","    from midi_ndarrays import *\n","    from midi_utils import download_midis\n","    download_midis(midi_data_dir)\n","\n","\n","def load_array(midi_filename):\n","    \"\"\"\n","    return midi_filename as a ndarray with start and end tokens\n","    Replace all notes with 1 - played, or 0 - not played\n","    \"\"\"\n","    midi_tracks = mido.MidiFile(midi_filename, clip=True)\n","    midi_array = mid2array(midi_tracks)\n","    \n","    # set all values to 1 or 0\n","    midi_array = np.where(midi_array != 0, 1, 0).astype('uint8')\n","    \n","    # add padding and encode start token (first column)\n","    # and end token (last column)\n","    midi_array = np.pad(midi_array, 1)\n","    midi_array[0, 0]   = 1\n","    midi_array[-1, -1] = 1\n","    \n","    return midi_array\n","\n","# if there aren't any csv files, convert all midis arrays and save in csv\n","if len(os.listdir(csv_data_dir)) == 0:\n","    for i in range(len(os.listdir(midi_data_dir))):\n","        midi_filename = dir_idx(midi_data_dir, i)\n","        midi_array = load_array(midi_filename)\n","        np.savetxt(midi_filename[:-4]+\".csv\", midi_array, fmt=\"%d\", delimiter=\",\")"]},{"cell_type":"markdown","id":"1c4f7a8b","metadata":{"id":"1c4f7a8b"},"source":["# The Model"]},{"cell_type":"code","execution_count":4,"id":"8f0840d8","metadata":{"id":"8f0840d8","executionInfo":{"status":"ok","timestamp":1651107478074,"user_tz":240,"elapsed":153,"user":{"displayName":"Lance Bergeron","userId":"12580516453162994131"}}},"outputs":[],"source":["class EncoderRNN(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_layers, dropout_p):\n","        super().__init__()\n","        \n","        self.input_size  = input_size\n","        self.hidden_size = hidden_size\n","        self.num_layers  = num_layers\n","        \n","        self.dropout   = nn.Dropout(dropout_p)\n","        self.embedding = nn.Embedding(input_size, hidden_size)\n","        self.rnn       = nn.LSTM(hidden_size, hidden_size, num_layers, dropout=dropout_p)\n","        \n","    def forward(self, x):\n","        # input dimension [1, 90]\n","        embedding = self.dropout(self.embedding(x))\n","        _, (h, c) = self.rnn(embedding)\n","        return h, c"]},{"cell_type":"code","execution_count":5,"id":"69d55259","metadata":{"id":"69d55259","executionInfo":{"status":"ok","timestamp":1651107481215,"user_tz":240,"elapsed":143,"user":{"displayName":"Lance Bergeron","userId":"12580516453162994131"}}},"outputs":[],"source":["class DecoderRNN(nn.Module):\n","    def __init__(self, input_size, hidden_size, output_size, \n","                num_layers, dropout_p):\n","    \n","        super().__init__()\n","        self.hidden_size = hidden_size\n","        self.num_layers  = num_layers\n","\n","        self.dropout   = nn.Dropout(dropout_p)\n","        self.embedding = nn.Embedding(input_size, hidden_size)\n","        \n","        self.rnn = nn.LSTM(hidden_size, hidden_size, num_layers, dropout=dropout_p)\n","        self.fc = nn.Linear(hidden_size, output_size)\n","        \n","    def forward(self, x, hidden, cell):\n","        x = x.unsqueeze(0)\n","        embedding = self.dropout(self.embedding(x))\n","\n","        outputs, (hidden, cell) = self.rnn(embedding, (hidden, cell))\n","        predictions = self.fc(outputs.squeeze(0))\n","\n","        # sigmoid because we're predicting multiple notes\n","        predictions = torch.sigmoid(predictions.squeeze(1))\n","\n","        # update all values over 0.5 to 1, else 0\n","        predictions = (predictions > 0.5).int()\n","        return predictions, hidden, cell"]},{"cell_type":"code","execution_count":7,"id":"3e057e12","metadata":{"id":"3e057e12","executionInfo":{"status":"ok","timestamp":1651107595809,"user_tz":240,"elapsed":164,"user":{"displayName":"Lance Bergeron","userId":"12580516453162994131"}}},"outputs":[],"source":["class Seq2Seq(nn.Module):\n","    \"\"\"\n","    Encapsulates the encoder and decoder. Pass a song matrix to the forward method, and it\n","    will encode it, then output the decoder's prediction of it\n","    \"\"\"\n","    def __init__(self, encoder, decoder):\n","        super().__init__()\n","        \n","        self.encoder = encoder\n","        self.decoder = decoder\n","  \n","    def forward(self, x, teacher_forcing_ratio=0.5):\n","        \"\"\"\n","        pre: x is the song on host not device - the gpu runs out of memory\n","             with the whole song\n","        \"\"\"\n","        # x: the song with shape [len, 90]\n","\n","        #tensor to store decoder outputs\n","        outputs = torch.zeros(x.shape)\n","        \n","        # encoder input song\n","        len_song = x.shape[0]\n","\n","        #h,c = 0,0\n","        # pass each row to the encoder one-by-one\n","        # for i in range(len_song):\n","        #     current_row = x[i,:].to(device)\n","        #     h,c = self.encoder(current_row.unsqueeze(0))\n","        \n","        print(\"pre encoder:\", torch.cuda.memory_allocated() / torch.cuda.max_memory_allocated())\n","        h,c = self.encoder(x.unsqueeze(0).to(device))\n","        print(\"post encoder:\", torch.cuda.memory_allocated() / torch.cuda.max_memory_allocated())\n","        #first input to the decoder is the <sos> tokens\n","        input = x[0,:].to(device)\n","\n","        # decode the length of the song and return prediction\n","        for t in range(1, len_song):\n","            \n","            #insert input token embedding, previous hidden and previous cell states\n","            #receive output tensor (predictions) and new hidden and cell states\n","            output, h, c = self.decoder(input, h, c)\n","\n","            #place predictions in a tensor holding predictions for each token\n","            outputs[t] = output.to(\"cpu\")\n","            \n","            #decide if we are going to use teacher forcing or not\n","            teacher_force = random.random() < teacher_forcing_ratio\n","            \n","            #if teacher forcing, use actual next token as next input\n","            #if not, use predicted token\n","            input = x[t,:].to(device) if teacher_force else output\n","\n","        memory_used = torch.cuda.memory_allocated() / torch.cuda.max_memory_allocated()\n","\n","        print(memory_used)\n","        \n","        return outputs\n","\n","    def generate_song(self, max_length):\n","        \"\"\"\n","        Generate a song based on the parameters of the encoder and decoder\n","        Pre: encoder and decoder should be optimized\n","        Return: The song as an song_length x 88 size numpy array\n","        \"\"\"\n","\n","        num_notes = self.encoder.input_size\n","\n","        song_matrix = torch.zeros(max_length, num_notes, dtype=torch.int)\n","\n","        # encode start token\n","        song_matrix[0, 0] = 1\n","\n","        # initial state is based on encoding the start token\n","        input = song_matrix[0, :].to(device)\n","\n","        h, c = self.encoder(input.unsqueeze(0))\n","\n","        # Predict the notes of this song following inputting the start token\n","        for t in range(1, max_length):\n","            # input is the predicted set of notes, and the input to the next\n","            # prediction\n","            input, h, c = self.decoder(input, h, c)\n","\n","            song_matrix[t] = input.to(\"cpu\")\n","\n","            # if end token is predicted: end\n","            if input[-1] == 0:\n","                print(\"end token\")\n","                break\n","\n","        print(\"t:\", t)\n","        # the song generated until the end token (or max_length)\n","        song_matrix = song_matrix[:t+1,:]\n","        \n","        # convert to np array\n","        song_matrix = np.array(song_matrix)\n","\n","        # trim outer padding for start and end tokens\n","        return song_matrix[1:-1, 1:-1]"]},{"cell_type":"markdown","id":"f0ef1ec3","metadata":{"id":"f0ef1ec3"},"source":["# Train"]},{"cell_type":"code","execution_count":8,"id":"5b60e717","metadata":{"id":"5b60e717","executionInfo":{"status":"ok","timestamp":1651107598603,"user_tz":240,"elapsed":491,"user":{"displayName":"Lance Bergeron","userId":"12580516453162994131"}}},"outputs":[],"source":["drop_p = 0.5\n","\n","# data has 88 columns for each piano note, plus two for start and end tokens\n","midi_dim = 90\n","\n","# model hyperparameters\n","hidden_size = 64\n","num_layers = 2\n","\n","# training hyperparemeters\n","num_epochs = 1\n","num_songs  = 1\n","\n","# the number of rows of the song matrix to pass to seq2seq --\n","# this is what I've found is the max you can use in colab without\n","# the free GPUs they provide running out of memory in decoding\n","batch_size = 20000\n","\n","save_model  = True\n","load_model  = False\n","train_model = True\n","model_filename = \"model.pt\""]},{"cell_type":"code","execution_count":9,"id":"2779875c","metadata":{"id":"2779875c","executionInfo":{"status":"ok","timestamp":1651107599568,"user_tz":240,"elapsed":182,"user":{"displayName":"Lance Bergeron","userId":"12580516453162994131"}}},"outputs":[],"source":["encoder = EncoderRNN(midi_dim, hidden_size, num_layers, drop_p)\n","decoder = DecoderRNN(midi_dim, hidden_size, 1, num_layers, drop_p)\n","model = Seq2Seq(encoder, decoder).to(device)\n","\n","optimizer = optim.Adam(model.parameters())\n","criterion = nn.BCELoss()"]},{"cell_type":"code","source":["midi_tensor = np.genfromtxt(dir_idx(csv_data_dir, 0), delimiter=',', dtype='int')\n","        \n","# convert to tensor\n","midi_tensor = torch.IntTensor(midi_tensor)"],"metadata":{"id":"wq68p0AyOAzK","executionInfo":{"status":"ok","timestamp":1651107617634,"user_tz":240,"elapsed":16294,"user":{"displayName":"Lance Bergeron","userId":"12580516453162994131"}}},"id":"wq68p0AyOAzK","execution_count":10,"outputs":[]},{"cell_type":"code","source":["num_songs = min(num_songs, len(os.listdir(csv_data_dir)))\n","\n","def train(model, num_songs):\n","    \"\"\"\n","    Pass num_songs to the model and optimize at each\n","    \"\"\"\n","    model.train()\n","\n","    epoch_loss = 0\n","\n","    for i in range(num_songs):\n","        optimizer.zero_grad()\n","\n","        # load song as numpy array\n","        # midi_tensor = np.genfromtxt(dir_idx(csv_data_dir, i), delimiter=',', dtype='int')\n","        \n","        # # convert to tensor\n","        # midi_tensor = torch.IntTensor(midi_tensor)\n","        \n","        # decode prediction\n","        predicted_song = model(midi_tensor)\n","        \n","        predicted_song.requires_grad = True\n","\n","        # optimize\n","        loss = criterion(predicted_song.float())\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","model_loaded = False\n","\n","# load the model\n","if load_model and model_filename in os.listdir():\n","    model.load_state_dict(torch.load(model_filename))\n","    model_loaded = True\n","\n","# train the model\n","if train_model:\n","    for epoch in range(num_epochs):\n","        train(model, num_songs)\n","\n","# save the model\n","if save_model and not model_loaded:\n","    torch.save(model.state_dict(), cwd+model_filename)"],"metadata":{"id":"JpTbCz7XDfm7","executionInfo":{"status":"error","timestamp":1651107622665,"user_tz":240,"elapsed":420,"user":{"displayName":"Lance Bergeron","userId":"12580516453162994131"}},"colab":{"base_uri":"https://localhost:8080/","height":389},"outputId":"b60d29f6-2013-42d2-a5e0-e8784b089f6b"},"id":"JpTbCz7XDfm7","execution_count":11,"outputs":[{"output_type":"error","ename":"ZeroDivisionError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-9440294e7036>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_songs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msave_model\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel_loaded\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-11-9440294e7036>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, num_songs)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# decode prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mpredicted_song\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmidi_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m20000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mpredicted_song\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-ea6ef257030f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, teacher_forcing_ratio)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m#     current_row = x[i,:].to(device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m#     h,c = self.encoder(current_row.unsqueeze(0))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pre encoder:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory_allocated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_memory_allocated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"post encoder:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory_allocated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_memory_allocated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"]}]},{"cell_type":"code","source":["# Passing data by batch\n","len_song = 100_001\n","\n","batch_size = 20_000\n","import math\n","num_batches = math.ceil(len_song / batch_size)\n","\n","song = np.arange(0, len_song)\n","\n","for i in range(num_batches):\n","    # last batch\n","    if i == num_batches-1:\n","        batch = song[i*batch_size:]\n","    else:\n","        batch = song[i*batch_size:(i+1)*batch_size]\n","\n","    print(batch)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gtUG2Fftr_eu","executionInfo":{"status":"ok","timestamp":1651108870696,"user_tz":240,"elapsed":178,"user":{"displayName":"Lance Bergeron","userId":"12580516453162994131"}},"outputId":"e1ca032a-008d-4cba-8ef9-3929298a1b7c"},"id":"gtUG2Fftr_eu","execution_count":70,"outputs":[{"output_type":"stream","name":"stdout","text":["[    0     1     2 ... 19997 19998 19999]\n","[20000 20001 20002 ... 39997 39998 39999]\n","[40000 40001 40002 ... 59997 59998 59999]\n","[60000 60001 60002 ... 79997 79998 79999]\n","[80000 80001 80002 ... 99997 99998 99999]\n","[100000]\n"]}]},{"cell_type":"code","source":["import gc\n","gc.collect()\n","torch.cuda.empty_cache()\n","torch.cuda.memory_allocated() / torch.cuda.max_memory_allocated()"],"metadata":{"id":"WAW88wCkNN0M"},"id":"WAW88wCkNN0M","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"colab":{"name":"main.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}